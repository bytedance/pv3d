config: null

model: null

datasets: []

# Configuration for models, default configuration files for various models
# included can be found under configs directory in root folder
model_config: {}

# Configuration for datasets, default configuration files for various datasets
# included can be found under configs directory in root folder
dataset_config: {}

# Configuration for training
training:
    # Name of the trainer class used to define the training/evalution loop
    # for default trainer, `lightning` for pytorch lightning trainer
    # pytorch lightning trainer's params is at `trainer.params`
    trainer: common
    # Seed to be used for training. -1 means random seed between 1 and 100000.
    # Either pass fixed through your config or command line arguments
    # Pass null to the seed if you don't want it seeded anyhow and
    # want to leave it to default
    seed: -1
    # Name of the experiment, will be used while saving checkpoints
    # and generating reports
    experiment_name: run
    # Maximum number of iterations the training will run
    max_updates: 30000
    # Maximum epochs in case you don't want to use max_updates
    # Can be mixed with max iterations, so it will stop whichever is
    # completed first. Default: null means epochs won't be used
    max_epochs: null

    # After `log_interval` updates, current update's training loss will be
    # reported. This will also report validation on a single batch from validation set
    # to provide an estimate on validation side
    log_interval: 100
    # Level of logging, only logs which are >= to current level will be logged
    logger_level: info
    # Log format: json, simple
    log_format: simple
    # Whether to log detailed final configuration parameters
    log_detailed_config: false
    # Whether log or not, Default: False, which means
    # will log by default
    should_not_log: false
    # Whether the colored logs should be used
    colored_logs: true

    # Tensorboard control, by default tensorboard is disabled
    tensorboard: false

    # Size of the batch globally. If distributed or data_parallel
    # is used, this will be divided equally among GPUs
    batch_size: 8
    # Size of the batch per GPU. Use this if you want to specify batch size
    # per GPU instead of global batch size.
    # Mutually exclusive with training.batch_size.
    batch_size_per_device: null
    # Run update_frequency=K batches with batch_size=N, accumulate gradients, then do
    # one update (one optimizer step). The effect is a large effective batch size of
    # KxN (without incurring the memory overhead of setting batch_size to KxN).
    update_frequency: 1
    # Number of workers to be used in dataloaders
    num_workers: 0
    # Whether to pin memory in dataloader
    pin_memory: false
    # Whether to drop the last batch in dataloader
    drop_last: true
    # Whether to use ema on model
    use_ema: false
    # Whether to clamp nan on gradients
    nan_to_num: false

    # This will visualize images/video on whole batch end after
    # visualize interval number of updates
    visualize_interval: 1000
    # After `checkpoint_interval` number of updates, it will make a snapshot
    # which will involve creating a checkpoint for current training scenarios
    checkpoint_interval: 1000
    # This will evaluate evaluation metrics on whole validation set after
    # evaluation interval number of updates
    evaluation_interval: 1000

    # Should a lr scheduler be used
    lr_scheduler: false

    # DEPRECATED: Look at scheduler_attributes or
    # Use PythiaScheduler directly instead
    # Steps for LR scheduler, will be an array of iteration count
    # when lr should be decreased
    lr_steps: []
    # DEPRECATED: Look at scheduler_attributes or
    # Use PythiaScheduler directly instead
    # Ratio for each lr step
    lr_ratio: 0.1

    # NOTE: Have a look at newer scheduler available (such as AdamW) before
    # using these options
    # Should use warmup for lr
    use_warmup: false
    # Warmup factor learning rate warmup
    warmup_factor: 0.2
    # Iteration until which warnup should be done
    warmup_iterations: 1000

    # Device on which the model will be trained. Set 'cpu' to train/infer on CPU
    device: cuda
    # Local rank of the GPU device
    local_rank: null

    visualization_online: false

    # If verbose dump is active, it will dump dataset, model specific
    # information which can be useful in debugging
    verbose_dump: false

    # Turn on if you want to ignore unused parameters in case of DDP
    find_unused_parameters: false

    # By default metrics evaluation is turned off during training. Set this to true
    # to enable evaluation every log_interval number of updates
    evaluate_metrics: false

    # This will enable anomaly detection mode in PyTorch. Use this for debugging
    # purposes if you see NaN issues in your experiments.
    # Warning: As per PyTorch docs, this usually slows down your code and should
    # only be used for debugging purposes
    detect_anomaly: false

    # FP16 support through torch.cuda.amp autocast and grad scaler.
    # Set to true to activate fp16 for faster performance with negligible
    # drop in results.
    fp16: false

    early_stop:
        # Whether to use early stopping, (Default: false)
        enabled: false
        # Patience for early stoppings
        patience: 4000
        # Criteria to be monitored for early stopping
        # total_loss will monitor combined loss from all of the tasks
        # Criteria can also be an evaluation metric in this format `dataset/metric`
        # for e.g. vqa2/vqa_accuracy
        criteria: total_loss
        # Whether the monitored criteria should be minimized for early stopping
        # or not, for e.g. you would want to minimize loss but maximize an evaluation
        # metric like accuracy etc.
        minimize: true

run_type: train_inference

# Configuration for optimizer, examples can be found in models' configs in
# configs folder
optimizer:
    # Whether to allow some of the model's parameters not to be used by the
    # optimizer. Default is false to guard against missing parameters due to
    # implementation errors in a model's get_optimizer_parameters
    allow_unused_parameters: false
    # Whether to enable optimizer state sharding. It uses ZeRO optimizer state
    # sharding method as described here https://arxiv.org/abs/1910.02054.
    enable_state_sharding: false

# Configuration for scheduler, examples can be found in models' configs
scheduler: {}

# Configuration for evaluation
evaluation:
    # Metrics for evaluation
    metrics: []
    # Use CPU for metrics and other calculations, you can use this option if
    # you see OOM in validation as in metrics are calculated globally
    use_cpu: false
    # Generate predictions in a file
    predict: false
    # Prediction file format (csv|json), default is json

# Configuration for the distributed setup
distributed:
    ###
    # Typically tcp://hostname:port that will be used to establish initial connection
    init_method: null
    # Rank of the current worker
    rank: 0
    # Port number, not required if using init_method,
    port: -1
    # Backend for distributed setup
    backend: nccl
    # Total number of GPUs across all nodes (default: all visible GPUs)
    world_size: ${device_count:}
    # Set if you do not want spawn multiple processes even if
    # multiple GPUs are visible
    no_spawn: false

env:
    # Universal cache directory
    # This can be overridden by using CACHE_DIR environment variable
    # or by directly setting this configuration attribute env.cache_dir
    # If nothing is specified, default is set to "." inside
    # pytorch's cache folder
    cache_dir: ${resolve_cache_dir:CACHE_DIR}

    # Directory for saving checkpoints and other metadata
    # Use SAVE_DIR or env.save_dir to override
    save_dir: ${oc.env:SAVE_DIR, ./save}

    # Directory for saving logs, default is "logs" inside the save folder
    # If log_dir is specifically passed, logs will be written inside that folder
    # Use LOG_DIR or env.log_dir to override
    log_dir: ${oc.env:LOG_DIR, ""}

    # Log directory for tensorboard, default points to same as logs
    # Only used when training.tensorboard is enabled.
    # Use TENSORBOARD_LOGDIR or env.tensorboard_logdir to override
    tensorboard_logdir: ${oc.env:TENSORBOARD_LOGDIR, ""}

    # Directory for saving everything except for tensorboard, default points to save folder 
    trial: ${resolve_trial:ARNOLD_OUTPUT, ""}

    # CUDA_VISIBLE_DEVICES
    visible_gpus: ${resolve_cuda_env:CUDA_VISIBLE_DEVICES, ""}

# Configuration for checkpointing including resuming and loading pretrained models
checkpoint:
    # If checkpoint.resume is true or 1, it will try to load automatically load
    # checkpoint and state from "current.ckpt" from env.save_dir
    resume: false
    # `checkpoint.resume_file` can be used to load a specific checkpoint from a file
    # Can also be a zoo key
    resume_file: null
    # `checkpoint.resume_best` will load the best checkpoint according to
    # training.early_stop.criteria instead of the last saved ckpt
    resume_best: false
    # `checkpoint.resume_pretrained` can be used in conjuction with `resume_file`
    # or `resume_zoo` where you specify a checkpoint or .pth file to be loaded
    # but it is mapped based on `checkpoint.pretrained_state_mapping`
    # For e.g. if you want to resume from visual_bert pretrained on coco
    # You would set `checkpoint.resume_zoo=visual_bert.pretrained.coco` and
    # then set `checkpoint.resume_pretrained=True` which will then pick up
    # only the base which you would define in the `checkpoint.pretrained_state_mapping`
    resume_pretrained: false
    # `checkpoint.resume_zoo` can be used to resume from a pretrained model provided
    # in zoo. Value maps to key from zoo. `checkpoint.resume_file` has higher
    # priority compared to `checkpoint.resume_zoo`.
    resume_zoo: null
    # `checkpoint.zoo_config_override` will override the current model config of trainer
    # with what is provided from the zoo checkpoint and will load the model
    # using .from_pretrained of the model passed
    zoo_config_override: false
    # `checkpoint.pretrained_state_mapping` specifies how exactly a pretrained
    # model will be loaded and mapped to which keys of the target model
    # Only use if the keys on the model in which pretrained model is to be loaded
    # don't match with those of the pretrained model or you only want to load specific
    # item from the pretrained model. `checkpoint.resume_pretrained` must be
    # true to use this mapping. for e.g. you can specify
    # text_embedding: text_embedding_pythia
    # for loading `text_embedding` module of your model from `text_embedding_pythia`of
    # pretrained file specified in `checkpoint.resume_file`.
    pretrained_state_mapping: {}

    # Will save only the last max_to_keep; if -1, saves all eligible checkpoints
    max_to_keep: -1

    # Whether to save git details or not
    save_git_details: true

    # `checkpoint.reset` configuration defines what exactly should be reset
    # in case the file from which we are resuming is .ckpt and not .pth
    reset:
        # Everything will be reset except the state_dict of model
        all: false
        # Optimizer specifically will be reset
        optimizer: false
        # All counts such as best_update, current_iteration etc will be reset
        counts: false
        # If fp16 scaler should be reset or not
        fp16_scaler: false